# Workflow agents
# motivated from: https://strandsagents.com/latest/user-guide/concepts/multi-agent/workflow/terms/workflow-agent/

import chat
import os
import logging
import sys
import re
import strands_agent
import json

from strands import Agent, tool

logging.basicConfig(
    level=logging.INFO,  
    format='%(filename)s:%(lineno)d | %(message)s',
    handlers=[
        logging.StreamHandler(sys.stderr)
    ]
)
logger = logging.getLogger("strands-agent")

index = 0
def add_notification(containers, message):
    global index
    containers['notification'][index].info(message)
    index += 1

def add_response(containers, message):
    global index
    containers['notification'][index].markdown(message)
    index += 1

status_msg = []
def get_status_msg(status):
    global status_msg
    status_msg.append(status)

    if status != "end)":
        status = " -> ".join(status_msg)
        return "[status]\n" + status + "..."
    else: 
        status = " -> ".join(status_msg)
        return "[status]\n" + status    

os.environ["BYPASS_TOOL_CONSENT"] = "true"

async def show_streams(agent_stream, containers):
    tool_name = ""
    result = ""
    current_response = ""

    async for event in agent_stream:
        # logger.info(f"event: {event}")
        if "message" in event:
            message = event["message"]
            logger.info(f"message: {message}")

            for content in message["content"]:                
                if "text" in content:
                    logger.info(f"text: {content['text']}")
                    if chat.debug_mode == 'Enable':
                        add_response(containers, content['text'])

                    result = content['text']
                    current_response = ""

                if "toolUse" in content:
                    tool_use = content["toolUse"]
                    logger.info(f"tool_use: {tool_use}")
                    
                    tool_name = tool_use["name"]
                    input = tool_use["input"]
                    
                    logger.info(f"tool_nmae: {tool_name}, arg: {input}")
                    if chat.debug_mode == 'Enable':       
                        add_notification(containers, f"tool name: {tool_name}, arg: {input}")
                        containers['status'].info(get_status_msg(f"{tool_name}"))
            
                if "toolResult" in content:
                    tool_result = content["toolResult"]
                    logger.info(f"tool_name: {tool_name}")
                    logger.info(f"tool_result: {tool_result}")
                    logger.info(f"tool_result status: {tool_result.get('status', 'unknown')}")
                    logger.info(f"tool_result toolUseId: {tool_result.get('toolUseId', 'unknown')}")
                    
                    if "content" in tool_result:
                        tool_content = tool_result['content']
                        logger.info(f"tool_content length: {len(tool_content)}")
                        for i, content in enumerate(tool_content):
                            logger.info(f"content[{i}]: {content}")
                            if "text" in content:
                                text_value = content['text']
                                logger.info(f"text_value: {text_value}")
                                logger.info(f"text_value type: {type(text_value)}")
                                
                                # ì½”ë£¨í‹´ ê°ì²´ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                                if isinstance(text_value, str) and '<coroutine object' in text_value:
                                    logger.info("Detected coroutine string, tool may still be executing...")
                                    if chat.debug_mode == 'Enable':
                                        add_notification(containers, f"tool result: Tool execution in progress...")
                                else:
                                    if chat.debug_mode == 'Enable':
                                        add_notification(containers, f"tool result: {text_value}")

        if "data" in event:
            text_data = event["data"]
            current_response += text_data

            if chat.debug_mode == 'Enable':
                containers["notification"][index].markdown(current_response)
            continue
    
    logger.info(f"show_streams completed, final result: {result}")
    logger.info(f"show_streams result type: {type(result)}")
    return result

def isKorean(text):
    # check korean
    pattern_hangul = re.compile('[\u3131-\u3163\uac00-\ud7a3]+')
    word_kor = pattern_hangul.search(str(text))
    # print('word_kor: ', word_kor)

    if word_kor and word_kor != 'None':
        # logger.info(f"Korean: {word_kor}")
        return True
    else:
        # logger.info(f"Not Korean:: {word_kor}")
        return False

async def run_graph(question, containers):
    global status_msg
    status_msg = []

    if chat.debug_mode == 'Enable':
        containers['status'].info(get_status_msg(f"(start"))    

    # Level 3 - Specialized Analysis Agents
    @tool
    async def market_research(query: str) -> str:
        """Analyze market trends and consumer behavior."""
        logger.info("ğŸ” Market Research Specialist analyzing...")
        market_agent = Agent(
            system_prompt="You are a market research specialist who analyzes consumer trends, market segments, and purchasing behaviors. Provide detailed insights on market conditions, consumer preferences, and emerging trends.",
            callback_handler=None
        )

        add_notification(containers, f"market_research: {query}")
        agent_stream = market_agent.stream_async(query)
        result = await show_streams(agent_stream, containers)
        logger.info(f"market_research completed, result: {result}")
        logger.info(f"market_research result type: {type(result)}")
        return result

    @tool
    async def financial_analysis(query: str) -> str:
        """Analyze financial aspects and economic implications."""
        logger.info("ğŸ’¹ Financial Analyst processing...")
        if isKorean(query):
            system_prompt = (
                "ë‹¹ì‹ ì€ ê²½ì œ ì˜ˆì¸¡, ë¹„ìš© íš¨ê³¼ ë¶„ì„, ê·¸ë¦¬ê³  ì¬ë¬´ ëª¨ë¸ë§ì— íŠ¹í™”ëœ ê²½ì œ ë¶„ì„ê°€ì…ë‹ˆë‹¤."
                "ì¬ë¬´ì  ê°€ì¹˜, ê²½ì œì  ì˜í–¥, ê·¸ë¦¬ê³  ì˜ˆì‚° ê³ ë ¤ì‚¬í•­ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•˜ì„¸ìš”."
            )
        else:
            system_prompt = (
                "You are a financial analyst who specializes in economic forecasting, cost-benefit analysis, and financial modeling. "
                 "Provide insights on financial viability, economic impacts, and budgetary considerations.",
            )
        financial_agent = Agent(
            system_prompt=system_prompt,
            callback_handler=None
        )

        add_notification(containers, f"financial_analysis: {query}")
        agent_stream = financial_agent.stream_async(query)
        result = await show_streams(agent_stream, containers)
        logger.info(f"financial_analysis completed, result: {result}")
        logger.info(f"financial_analysis result type: {type(result)}")

        return result

    @tool
    async def technical_analysis(query: str) -> str:
        """Analyze technical feasibility and implementation challenges."""
        logger.info("âš™ï¸ Technical Analyst evaluating...")
        if isKorean(query):
            system_prompt = (
                "ë‹¹ì‹ ì€ ê¸°ìˆ ì  ê°€ëŠ¥ì„±, êµ¬í˜„ ì±Œë¦°ì§€, ê·¸ë¦¬ê³  ìƒˆë¡œìš´ ê¸°ìˆ ì— ëŒ€í•œ í‰ê°€ë¥¼ í•˜ëŠ” ê¸°ìˆ  ë¶„ì„ê°€ì…ë‹ˆë‹¤."
                "ê¸°ìˆ ì  ì¸¡ë©´, êµ¬í˜„ ìš”êµ¬ì‚¬í•­, ê·¸ë¦¬ê³  ì ì¬ì  ê¸°ìˆ ì  ì¥ì• ì— ëŒ€í•œ ìì„¸í•œ í‰ê°€ë¥¼ ì œê³µí•˜ì„¸ìš”."
            )
        else:
            system_prompt = (
                "You are a technology analyst who evaluates technical feasibility, implementation challenges, and emerging technologies. "
                "Provide detailed assessments of technical aspects, implementation requirements, and potential technological hurdles."
            )

        tech_agent = Agent(
            system_prompt=system_prompt,
            callback_handler=None
        )

        add_notification(containers, f"technical_analysis: {query}")
        agent_stream = tech_agent.stream_async(query)
        result = await show_streams(agent_stream, containers)
        logger.info(f"technical_analysis completed, result: {result}")
        logger.info(f"technical_analysis result type: {type(result)}")

        return result

    @tool
    async def social_analysis(query: str) -> str:
        """Analyze social impacts and behavioral implications."""
        logger.info("ğŸ‘¥ Social Impact Analyst investigating...")

        if isKorean(query):
            system_prompt = (
                "ë‹¹ì‹ ì€ ë³€í™”ê°€ ì§€ì—­ì‚¬íšŒ, í–‰ë™, ê·¸ë¦¬ê³  ì‚¬íšŒ êµ¬ì¡°ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ì´ˆì ì„ ë§ì¶˜ ì‚¬íšŒì  ì˜í–¥ ë¶„ì„ê°€ì…ë‹ˆë‹¤."
                "ì‚¬íšŒì ì¸ ì˜ë¯¸, ì˜ˆì¸¡ë˜ëŠ” í–‰ë™ ë³€í™”, ê·¸ë¦¬ê³  ì§€ì—­ì‚¬íšŒ ì˜í–¥ì— ëŒ€í•œ í†µì°°ì„ ì œê³µí•˜ì„¸ìš”."
            )            
        else:
            system_prompt = (
                "You are a social impact analyst who focuses on how changes affect communities, behaviors, and social structures. "
                "Provide insights on social implications, behavioral changes, and community impacts."
            )            
        
        social_agent = Agent(
            system_prompt=system_prompt,
            callback_handler=None
        )

        add_notification(containers, f"social_analysis: {query}")
        agent_stream = social_agent.stream_async(query)
        result = await show_streams(agent_stream, containers)
        logger.info(f"social_analysis completed, result: {result}")
        logger.info(f"social_analysis result type: {type(result)}")

        return result

    # Level 2 - Mid-level Manager Agent with its own specialized tools
    @tool
    async def economic_department(query: str) -> str:
        """Coordinate economic analysis across market and financial domains."""
        logger.info("ğŸ“ˆ Economic Department coordinating analysis...")

        if isKorean(query):
            system_prompt = (
                "ë‹¹ì‹ ì€ ê²½ì œ ë¶€ì„œ ê´€ë¦¬ìì…ë‹ˆë‹¤. ê²½ì œ ë¶„ì„ì„ ì¡°ì •í•˜ê³  í†µí•©í•©ë‹ˆë‹¤."
                "ì‹œì¥ ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” market_research ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
                "ê²½ì œì  ì§ˆë¬¸ì—ëŠ” financial_analysis ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
                "ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ í†µí•©ëœ ê²½ì œ ê´€ì ì„ ì œê³µí•˜ì„¸ìš”."
                "ì¤‘ìš”: ì§ˆë¬¸ì´ ëª…í™•í•˜ê²Œ í•œ ì˜ì—­ì— ì§‘ì¤‘ë˜ì§€ ì•ŠëŠ” í•œ ë‘ ë„êµ¬ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ ì² ì €í•œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
            )
        else:
            system_prompt = (
                "You are an economic department manager who coordinates specialized economic analyses. "
                "For market-related questions, use the market_research tool. "
                "For financial questions, use the financial_analysis tool. "
                "Synthesize the results into a cohesive economic perspective. "
                "Important: Make sure to use both tools for comprehensive analysis unless the query is clearly focused on just one area."
            )

        econ_manager = Agent(
            system_prompt=system_prompt,
            tools=[market_research, financial_analysis],
            callback_handler=None
        )

        add_notification(containers, f"economic_department: {query}")
        agent_stream = econ_manager.stream_async(query)
        result = await show_streams(agent_stream, containers)
        logger.info(f"economic_department completed, result: {result}")
        logger.info(f"economic_department result type: {type(result)}")

        return result

    if isKorean(question):
        COORDINATOR_SYSTEM_PROMPT = (
            "ë‹¹ì‹ ì€ ë³µì¡í•œ ë¶„ì„ì„ ì´ê´„í•˜ëŠ” ìµœê³  ê²½ì˜ìì…ë‹ˆë‹¤."
            "ê²½ì œì  ì§ˆë¬¸ì—ëŠ” economic_department ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
            "ê¸°ìˆ ì  ì§ˆë¬¸ì—ëŠ” technical_analysis ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
            "ì‚¬íšŒì  ì§ˆë¬¸ì—ëŠ” social_analysis ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
            "ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ í†µí•©ëœ ê²½ì œ ê´€ì ì„ ì œê³µí•˜ì„¸ìš”."
        )
    else:
        COORDINATOR_SYSTEM_PROMPT = (
            "You are an executive coordinator who oversees complex analyses across multiple domains."        
            "For economic questions, use the economic_department tool. "
            "For technical questions, use the technical_analysis tool. "
            "For social impact questions, use the social_analysis tool. "
            "Synthesize all analyses into comprehensive executive summaries. "
            "Your process should be: "
            "1. Determine which domains are relevant to the query (economic, technical, social) "
            "2. Collect analysis from each relevant domain using the appropriate tools "
            "3. Synthesize the information into a cohesive executive summary "
            "4. Present findings with clear structure and organization "
            "Always consider multiple perspectives and provide balanced, well-rounded assessments. "
        )

    # Create the coordinator agent with all tools
    coordinator = Agent(
        system_prompt=COORDINATOR_SYSTEM_PROMPT,
        tools=[economic_department, technical_analysis, social_analysis],
        callback_handler=None
    )

    add_notification(containers, f"ì§ˆë¬¸: {question}")
    agent_stream = coordinator.stream_async(f"Provide a comprehensive analysis of: {question}")
    result = await show_streams(agent_stream, containers)
    logger.info(f"coordinator result: {result}")

    if chat.debug_mode == 'Enable':
        containers['status'].info(get_status_msg(f"end)"))

    return result
